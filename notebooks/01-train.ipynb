{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I want to be able to\n",
    "\n",
    "- Specify my own bigwigs together with control experiments\n",
    "- Use the same control experiment for multiple tracks\n",
    "- Train only in peak regions or genome-wide\n",
    "- Train on AWS and in Colab notebook\n",
    "- Fully utilize my GPU without waiting for data-loading\n",
    "- Easily try out multiple hyper-parameters\n",
    "- See all the logs and evaluation metrics in the file\n",
    "- See all the logs on comet.ml or similar website\n",
    "- Visualize the loss curves and see some example predictions (observed vs predicted) afterwards\n",
    "- Use my own evaluation notebook\n",
    "- Have a good set of default hyper-parameters for each assay (ChIP-nexus and ChIP-seq)\n",
    "- Train on multiple assays simultaneously\n",
    "- Train on any functional genomics assay where events result in coverage peaks\n",
    "  - ChIP-nexus\n",
    "  - ChIP-seq\n",
    "  - DNase\n",
    "  - eClip\n",
    "  - CutNRun\n",
    "- Specify my own architecture, loss function, training function if needed\n",
    "\n",
    "## Implementation\n",
    "\n",
    "- Load the data into memory if possible\n",
    "- Use gin-config files for specifying architectures, loss functions etc\n",
    "  - Note: You have to educate users about it. It may be too complicated.\n",
    "- Use SeqModel\n",
    "- Use the default model without specifying any hyper-parameters for different kinds of data\n",
    "- Don't save the pkl file\n",
    "- Infer the number of tasks from dataspec\n",
    "\n",
    "\n",
    "## Args\n",
    "\n",
    "- `<dataspec>`: dataspec.yaml\n",
    "- `--config=model.gin` (gin config files specifying the model architecture and the loss etc)\n",
    "- `--premade=bpnet9`: pre-made config file to use (e.g. use the default architecture). The user could override the setting using bindings.\n",
    "- `--override`: model/loss/training parameters to override\n",
    "- `--evaluate` If true, the model will also be evaluated on the \n",
    "- `--report`: path to the ipynb report file. Use the default one.\n",
    "\n",
    "## Output\n",
    "\n",
    "- train.log\n",
    "- model.h5\n",
    "- evaluate.html\n",
    "- evaluate.ipynb\n",
    "- model.gin -> copied from the input\n",
    "- dataspec.yaml -> copied from the input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- specify only a single track\n",
    "  - do we really need to specify pos_track and neg_track explicitly or can we just list them? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training BPNet on your own data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/bpnet-arch.png\" alt=\"BPNet\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Specify data -> write `dataspec.yml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step requires specifying the data on which to train the model. BPNet takes as input nucleotide sequence and outputs the read coverage profile for multiple tracks at base-resolution. The coverage tracks can come from any genome-wide functional genomics assay that has a sufficient spatial resolution including ChIP-nexus, ChIP-exo, ChIP-seq, DNase-seq, and ATAC-seq. Additionally, different experiments may have differnet biases that need to be accounted for. Both, the signal and the bias/control tracks have to be stored in [BigWig](https://genome.ucsc.edu/goldenpath/help/bigWig.html) files.\n",
    "\n",
    "In this tutorial, we will use the data from the BPNet paper (TODO - link) measuring TF binding of 4 TFs (Oct4, Sox2, Nanog and Klf4) with ChIP-nexus in mouse embryonic stem cells (mESCs). To make things faster, we will focus only on a small subset of the regions.\n",
    "\n",
    "- [ ] describe `dataspec.yml`\n",
    "  - give one example\n",
    "  - explain each entry in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget ....\n",
    "#!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataspec.yaml` for these data looks as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "fasta_file: ./reference-genome.fa\n",
    "task_specs:\n",
    "  task1:\n",
    "    pos_counts: ./task1.pos.bigWig\n",
    "    neg_counts: ./task1.neg.bigWig\n",
    "    peaks: ./task1.peaks.bed.gz  # optional. Peaks associated with task1\n",
    "    \n",
    "    # optional\n",
    "    ignore_strand: False  # if True, use the sum of pos_ and neg_counts\n",
    "    bias_bigwig: ./InputDNA.counts.bigWig  # measured bias. IP in ChIP-seq\n",
    "    bias_model: null   # sequence-based bias model\n",
    "  task2:\n",
    "    ...  # similarly as for task1\n",
    "  task3:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasta_file: data/mm10_no_alt_analysis_set_ENCODE.fasta\n",
      "task_specs:\n",
      "  Oct4:\n",
      "    pos_counts: data/Oct4/counts.pos.bw\n",
      "    neg_counts: data/Oct4/counts.neg.bw\n",
      "    peaks: data/Oct4/idr-optimal-set.summit.bed.gz\n",
      "  Sox2:\n",
      "    pos_counts: data/Sox2/counts.pos.bw\n",
      "    neg_counts: data/Sox2/counts.neg.bw\n",
      "    peaks: data/Sox2/idr-optimal-set.summit.bed.gz\n",
      "  Nanog:\n",
      "    pos_counts: data/Nanog/counts.pos.bw\n",
      "    neg_counts: data/Nanog/counts.neg.bw\n",
      "    peaks: data/Nanog/idr-optimal-set.summit.bed.gz\n",
      "  Klf4:\n",
      "    pos_counts: data/Klf4/counts.pos.bw\n",
      "    neg_counts: data/Klf4/counts.neg.bw\n",
      "    peaks: data/Klf4/idr-optimal-set.summit.bed.gz\n",
      "\n",
      "bias_specs:\n",
      "  input:\n",
      "    pos_counts: data/patchcap/counts.pos.bw\n",
      "    neg_counts: data/patchcap/counts.neg.bw\n",
      "    tasks:\n",
      "      - Oct4\n",
      "      - Sox2\n",
      "      - Nanog\n",
      "      - Klf4"
     ]
    }
   ],
   "source": [
    "!cat dataspec.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dataspec.yml` file contains three parts:\n",
    "- `task_specs`\n",
    "- `bias_specs`\n",
    "- `fasta_file`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Before you jump ahead and start training the model, we recommend eyeballing the coverage tracks (BigWig) and peak regions (bed) using the genome browser such as the [WashU](https://epigenomegateway.wustl.edu/) or [IGV](https://software.broadinstitute.org/software/igv/). If you can not identify peaks by eye then the model will not be able to do it either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `DataSpec` to visualize the raw data\n",
    "\n",
    "Having specified your data in `dataspec.yml`, you can use also `bpnet.specs.DataSpec` to parse the file and visualize the tracks for a specific genomic interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO - show how to do that. Show the Oct4 enhancer from the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do I get my data into a BigWig file?\n",
    "\n",
    "Functional genomics experiments based on sequencing yield many short reads which then get aligned to the reference genome. The alignment locations of the reads are typically stored in the [BAM](http://samtools.github.io/hts-specs/SAMv1.pdf) file. There are different ways of computing the coverage from aligned reads. To prevent loosing any spatial information in the profiles, we would like to generate non-smoothed tracks (as raw as possible). For ChIP-exo/nexus/seq experiments this means counting the 5' locations of the reads. Note that the aligned reads also have strand information hence we will generate two coverage tracks, one for the positive/forward and one for the negative/reverse strand. If multiple technical or biological replicate experiments were performed for a specific transcription factor, we will simply add up the coverage tracks.\n",
    "\n",
    "The `bpnet` CLI offers a simple convenience command to convert the read alignments stored in the BAM file into the coverage tracks.\n",
    "\n",
    "```bash\n",
    "bpnet align2bigwig <rep1.bam> <rep2.bam> --fragment-point=5prime --strand-spec <output prefix>\n",
    "```\n",
    "\n",
    "For more information run `bpnet align2bigwig --help` or read the source code here (TODO - link). Note that `align2bigwig` also accepts the `TagAlign` file generated by the ENCODE ChIP-seq pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO - show the read coverage profile for chip-seq and the 5' ends of the reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do I get `regions.bed`?\n",
    "\n",
    "For large genomes such as human or mouse, training genome-wide can be computationally expensive. Most of the regions in the genome will contain very little counts, hence the model will not recieve a lot of information. We can significantly speed up the training process by training the model only in regions with higher number of counts. These regions are determined using traditional peak callers such as MACS2. Since we just want to discard regions with little or no counts, we don't care about the exact peak locations or even high false positive rates. Hence almost any peak caller should be fine.\n",
    "\n",
    "You can also train the model genome-wide by tiling the genome into bins (using say stride of 400). You can generate the intervals of the tiled genome using - TODO - refer to dataloader tools?. BPNet also allows you to sample regions overlapping a known peak with higher probability. Then you have to provide the `TODO dataloader command` with the peak locations. In that case, the produced bed file will be a tsv file looking as follows\n",
    "\n",
    "```tsv\n",
    "CHROM    START    END   task1   task2   ...\n",
    " chr1    10000  11000       1       0\n",
    "\n",
    "```\n",
    "\n",
    "Columns following the interval coordinates specify whether the center of the interval overlapped a peak from `task1` (1=yes) or `task2` (0=no)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can I train the model without the bias track?\n",
    "\n",
    "Technically, yes. It will work well for assays with low amount of bias such as ChIP-exo or ChIP-nexus. However, we generally recommend using the bias track. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Specify model architecture -> use pre-made models or write `model.gin`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I want to train a model on ChIP-seq. How can I do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I want to train a model on DNase-seq or ATAC-seq. How can I do this?\n",
    "\n",
    "The key difference between DNase-seq and ChIP-seq/exo is that DNase-seq coverage is not strand specific. Hence a single BigWig file is required. By contrast, ChIP-seq required two BigWigs - one for the positive and one for the negative strand. Beware that controlling for DNase biases is still an open question and you should think carefully about it.\n",
    "\n",
    "Otherwise, you can just specify a similar `dataspec.yml` as before:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "TODO: write\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
